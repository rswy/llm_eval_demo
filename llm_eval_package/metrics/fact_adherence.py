# llm_eval_package/metrics/fact_adherence.py
from llm_eval_package.metrics.base import BaseMetric
import re

class FactAdherenceMetric(BaseMetric):
    """
    A metric to evaluate if a list of required facts are present in the LLM output.
    """

    def __init__(self):
        super().__init__("Fact Adherence")

    def compute(self, llm_output: str, reference_answer: str = None, query: str = None, required_facts: str = None, **kwargs) -> float:
        """
        Computes the fact adherence score.

        Args:
            llm_output (str): The output generated by the LLM.
            reference_answer (str, optional): Not directly used by this metric for scoring, but part of base signature.
            query (str, optional): Not directly used by this metric, but part of base signature.
            required_facts (str, optional): A string containing facts separated by a semicolon (`;`).
                                           Example: "fact one; fact two; fact three"
            **kwargs: Additional keyword arguments.

        Returns:
            float: Proportion of required facts found in the llm_output.
                   Returns 1.0 if required_facts is empty or None (no facts to check).
        """
        if not required_facts or not required_facts.strip():
            return 1.0  # No facts required, so adherence is 100%

        facts_list = [fact.strip() for fact in required_facts.split(';') if fact.strip()]

        if not facts_list:
            return 1.0 # No valid facts provided after splitting

        found_count = 0
        llm_output_lower = llm_output.lower() if llm_output else ""

        for fact in facts_list:
            # Using regex for case-insensitive whole word/phrase matching for better accuracy
            # This simple check looks for the fact as a substring, case-insensitively.
            # For more complex matching (e.g., semantic), a more advanced technique would be needed.
            # For UAT, explicit string presence is often a good starting point.
            # We escape special regex characters in the fact itself.
            pattern = r"\b" + re.escape(fact.lower()) + r"\b" # \b for word boundaries
            try:
                if re.search(pattern, llm_output_lower):
                    found_count += 1
            except re.error as e:
                print(f"Regex error for fact '{fact}': {e}. Skipping this fact.")
                # Optionally, you might want to adjust total_facts if a fact causes a regex error
                # For now, it counts as not found if the pattern is invalid.

        return found_count / len(facts_list) if len(facts_list) > 0 else 1.0

    def get_score_description(self, score: float) -> str:
        if score == 1.0:
            return "Excellent: All required facts were found in the LLM output."
        elif score >= 0.75:
            return "Good: Most of the required facts were found."
        elif score >= 0.5:
            return "Moderate: Some required facts were found, but several are missing."
        elif score > 0.0:
            return "Low: Very few required facts were found."
        else: # score == 0.0
            return "Poor: None of the required facts were found in the LLM output."